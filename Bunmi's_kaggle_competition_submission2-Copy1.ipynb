{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Name : Akinremi Bunmi Josephine.\n",
    "\n",
    "<h3>kaggle_Id : bumie.\n",
    "\n",
    "<h3>Student_Status: 100 level.\n",
    "\n",
    "<h3>Gender : Female.\n",
    "\n",
    "<h3>Special_Services : AI+ Club Campus Co-ordinator\n",
    "\n",
    "<h3>Name_of_School : Obafemi Awolowo University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most Important\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import the testdata, train data, submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "sam = pd.read_csv('sample_submission2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Lets take a brief look at the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trainings_Attended</th>\n",
       "      <th>Year_of_birth</th>\n",
       "      <th>Last_performance_score</th>\n",
       "      <th>Year_of_recruitment</th>\n",
       "      <th>Targets_met</th>\n",
       "      <th>Previous_Award</th>\n",
       "      <th>Training_score_average</th>\n",
       "      <th>Promoted_or_Not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>38312.000000</td>\n",
       "      <td>38312.000000</td>\n",
       "      <td>38312.000000</td>\n",
       "      <td>38312.000000</td>\n",
       "      <td>38312.000000</td>\n",
       "      <td>38312.000000</td>\n",
       "      <td>38312.000000</td>\n",
       "      <td>38312.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.253680</td>\n",
       "      <td>1986.209334</td>\n",
       "      <td>7.698959</td>\n",
       "      <td>2013.139695</td>\n",
       "      <td>0.352996</td>\n",
       "      <td>0.023152</td>\n",
       "      <td>55.366465</td>\n",
       "      <td>0.084595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.609443</td>\n",
       "      <td>7.646047</td>\n",
       "      <td>3.744135</td>\n",
       "      <td>4.261451</td>\n",
       "      <td>0.477908</td>\n",
       "      <td>0.150388</td>\n",
       "      <td>13.362741</td>\n",
       "      <td>0.278282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1982.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1982.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1988.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1992.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>2001.000000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Trainings_Attended  Year_of_birth  Last_performance_score  \\\n",
       "count        38312.000000   38312.000000            38312.000000   \n",
       "mean             2.253680    1986.209334                7.698959   \n",
       "std              0.609443       7.646047                3.744135   \n",
       "min              2.000000    1950.000000                0.000000   \n",
       "25%              2.000000    1982.000000                5.000000   \n",
       "50%              2.000000    1988.000000                7.500000   \n",
       "75%              2.000000    1992.000000               10.000000   \n",
       "max             11.000000    2001.000000               12.500000   \n",
       "\n",
       "       Year_of_recruitment   Targets_met  Previous_Award  \\\n",
       "count         38312.000000  38312.000000    38312.000000   \n",
       "mean           2013.139695      0.352996        0.023152   \n",
       "std               4.261451      0.477908        0.150388   \n",
       "min            1982.000000      0.000000        0.000000   \n",
       "25%            2012.000000      0.000000        0.000000   \n",
       "50%            2014.000000      0.000000        0.000000   \n",
       "75%            2016.000000      1.000000        0.000000   \n",
       "max            2018.000000      1.000000        1.000000   \n",
       "\n",
       "       Training_score_average  Promoted_or_Not  \n",
       "count            38312.000000     38312.000000  \n",
       "mean                55.366465         0.084595  \n",
       "std                 13.362741         0.278282  \n",
       "min                 31.000000         0.000000  \n",
       "25%                 43.000000         0.000000  \n",
       "50%                 52.000000         0.000000  \n",
       "75%                 68.000000         0.000000  \n",
       "max                 91.000000         1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> We can see that the train dataset has 38312 rows and 19 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Lets take a brief look at the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> We can see that the test dataset has 16496 columns and 18 rows</b>\n",
    "\n",
    "<h3> Does our dataset contain any null value? Lets find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Hmmn, we can see that the column \"Qualification\" has only 36633 of its values that are not null. \n",
    "<h3> We can also see the various datatypes present in the dataset.(We'll deal with these later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Lets divide the dataset into biased and unbiased. \n",
    "    \n",
    "\n",
    "<h3>Lets first take a look at the unbiased dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>The Unbiased dataset contains the following columns: Qualification, Target_met, Previous_Award, Trainning_Score_Average,\n",
    "<h4>Foregin_Schooled, Past_Disiciplanry_Action, Previous_Intradepartmental_Movement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> First of all, lets create a dataframe containing the test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itrain = train\n",
    "itest = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Lets Review the Qualification Column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Qualification.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>For better view let's plot these columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(x, y):\n",
    "    fig, ax = plt.subplots(figsize = (13, 4))\n",
    "    sns.barplot(x, y)\n",
    "    plt.xlabel('x', fontSize=13)\n",
    "    plt.xticks(rotation='90')\n",
    "    plt.ylabel('Promoted_or_Not', fontSize=13)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test.Qualification\n",
    "y = itrain.Promoted_or_Not\n",
    "\n",
    "plot_graph(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(18,8))\n",
    "train['Qualification'].value_counts().plot.pie(explode=[0,0.1,0.2],autopct='%1.1f%%',ax=ax[0], shadow=True)\n",
    "ax[0].set_title('Qualification vs promotion')\n",
    "ax[0].set_ylabel('Qualification')\n",
    "sns.factorplot('Qualification', 'Promoted_or_Not',data=train,ax=ax[1])\n",
    "ax[1].set_title('Qualification vs promotion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h4> From the above, we can say that more of the"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets Review the Target_met column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Targets_met.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot('Targets_met','Promoted_or_Not',hue='Targets_met',data=train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(18,8))\n",
    "train[['Targets_met','Promoted_or_Not']].groupby(['Targets_met']).mean().plot.bar(ax=ax[0])\n",
    "ax[0].set_title('Targets_met vs Promoted_or_Not')\n",
    "sns.countplot('Targets_met',hue='Promoted_or_Not',data=train,ax=ax[1])\n",
    "ax[1].set_title('Targets_met:Promoted or Not')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test.Targets_met\n",
    "y = itrain.Promoted_or_Not\n",
    "\n",
    "plot_graph(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets review the Previous_Award column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Previous_Award.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets Review the Promoted_or_Not Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For better view let's plot these percents!\n",
    "x = test.Previous_Award\n",
    "y = itrain.Promoted_or_Not\n",
    "\n",
    "plot_graph(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(20,8))\n",
    "sns.barplot('Previous_Award','Promoted_or_Not',data=train,ax=ax[0])\n",
    "ax[0].set_title('Previous_Award vs Promoted_or_Not')\n",
    "sns.factorplot('Previous_Award','Promoted_or_Not',data=train,ax=ax[1])\n",
    "ax[1].set_title('Previous_Award vs Promoted_or_Not')\n",
    "plt.close(2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot('Previous_Award','Promoted_or_Not',hue='Previous_Award',data=train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets review the Trainning score average column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train.Training_score_average\n",
    "y = itrain.Promoted_or_Not\n",
    "\n",
    "plot_graph(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot('Training_score_average','Promoted_or_Not',data=train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets review the Foregin_Schooled column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Foreign_schooled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test.Foreign_schooled\n",
    "y = itrain.Promoted_or_Not\n",
    "\n",
    "plot_graph(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(20,8))\n",
    "sns.distplot(train[train['Foreign_schooled']=='Yes'].Promoted_or_Not,ax=ax[0])\n",
    "ax[0].set_title('Schooled Aborad:Yes')\n",
    "sns.distplot(train[train['Foreign_schooled']=='No'].Promoted_or_Not,ax=ax[1])\n",
    "ax[1].set_title('Schooled Abroad:No')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at the Past_Disciplinary_Action column!,\n",
    "\n",
    "And see those who has been disciplined(bad boys) before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Past_Disciplinary_Action.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot('Past_Disciplinary_Action','Promoted_or_Not',data=train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test.Past_Disciplinary_Action\n",
    "y = itrain.Promoted_or_Not\n",
    "\n",
    "plot_graph(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(20,8))\n",
    "sns.distplot(train[train['Past_Disciplinary_Action']=='Yes'].Promoted_or_Not,ax=ax[0])\n",
    "ax[0].set_title('Past_Disciplinary_Action:Yes')\n",
    "sns.distplot(train[train['Past_Disciplinary_Action']=='No'].Promoted_or_Not,ax=ax[1])\n",
    "ax[1].set_title('Past_Disciplinary_Action:No')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at the Previous_Intradepartmental_Movement column. Some might have even been promoted before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot('Previous_IntraDepartmental_Movement','Promoted_or_Not',data=train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = itrain.Previous_IntraDepartmental_Movement\n",
    "y = itrain.Promoted_or_Not\n",
    "\n",
    "plot_graph(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(18,8))\n",
    "train[['Previous_IntraDepartmental_Movement','Promoted_or_Not']].groupby(['Previous_IntraDepartmental_Movement']).mean().plot.bar(ax=ax[0])\n",
    "ax[0].set_title('Previous_IntraDepartmental_Movement vs Promoted_or_Not')\n",
    "sns.countplot('Previous_IntraDepartmental_Movement',hue='Promoted_or_Not',data=train,ax=ax[1])\n",
    "ax[1].set_title('Previous_IntraDepartmental_Movement:Promoted or Not')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(20,15))\n",
    "sns.countplot('Previous_IntraDepartmental_Movement',data=train,ax=ax[0])\n",
    "ax[0].set_title('Previous_IntraDepartmental_Movement')\n",
    "sns.countplot('Previous_IntraDepartmental_Movement',hue='Promoted_or_Not',data=train,ax=ax[1])\n",
    "ax[1].set_title('Previous_IntraDepartmental_Movement for Promoted_or_Not')\n",
    "plt.subplots_adjust(wspace=0.2,hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, after we are done with that, lets take a look at the Biased dataset.\n",
    "\n",
    "<h4>The Biased dataset contains the following : </h4>\n",
    "Division, Marital_Status, Gender, Channel_of_Recruitment, Year_of_birth, Trainings_Attended, Last_performance_score, No_of_previous employers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train.Division\n",
    "y = train.Promoted_or_Not\n",
    "plot_graph(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test.Division\n",
    "y = train.Promoted_or_Not\n",
    "plot_graph(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot('Division', 'Promoted_or_Not',data=train)\n",
    "plt.xlabel('Division Columns', fontSize=13)\n",
    "plt.xticks(rotation='90')\n",
    "plt.ylabel('Promoted_or_Not', fontSize=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y,x,orient = 'h')\n",
    "plt.grid('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(18,8))\n",
    "train['Division'].value_counts().plot.pie(explode=[0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8],autopct='%1.1f%%',ax=ax[0], shadow=True)\n",
    "ax[0].set_title('Division vs promotion')\n",
    "ax[0].set_ylabel('Division')\n",
    "sns.factorplot('Division', 'Promoted_or_Not',data=train,ax=ax[1])\n",
    "ax[1].set_title('Division vs promotion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> From these, we can see that this column is biased as some divisions are more promoted than some"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itrain.Gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test.Gender\n",
    "y = train.Promoted_or_Not\n",
    "\n",
    "plot_graph(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For better view let's plot these percents!\n",
    "x = train.Gender\n",
    "y = train.Promoted_or_Not\n",
    "\n",
    "plot_graph(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(20,8))\n",
    "train['Gender'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%',ax=ax[0], shadow=True)\n",
    "ax[0].set_title('Gender vs Promoted_or_Not')\n",
    "sns.factorplot('Gender','Promoted_or_Not',data=train,ax=ax[1])\n",
    "ax[1].set_title('Gender vs Promoted_or_Not')\n",
    "plt.close(2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> From here, we can see that there are more males than females but, more females are promoted than males!\n",
    "    \n",
    "<h3> Lets look at the Channel_of_Recruitment column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Channel_of_Recruitment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test.Channel_of_Recruitment\n",
    "y = itrain.Promoted_or_Not\n",
    "\n",
    "plot_graph(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For better view let's plot these percents!\n",
    "x = train.Channel_of_Recruitment\n",
    "y = train.Promoted_or_Not\n",
    "\n",
    "plot_graph(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(20,8))\n",
    "sns.barplot('Channel_of_Recruitment','Promoted_or_Not',data=train,ax=ax[0])\n",
    "ax[0].set_title('Channel_of_Recruitment vs Promoted_or_Not')\n",
    "sns.factorplot('Channel_of_Recruitment','Promoted_or_Not',data=train,ax=ax[1])\n",
    "ax[1].set_title('Channel_of_Recruitment vs Promoted_or_Not')\n",
    "plt.close(2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Am sure you'll agree that with me that those who had special referral even got promoted than those who cme through the normal qualified way\n",
    "    \n",
    "<h3> So now, Lets take a look at the Trainings_Attended column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Trainings_Attended.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train.Trainings_Attended\n",
    "y = train.Promoted_or_Not\n",
    "\n",
    "plot_graph(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y,x,orient = 'h')\n",
    "plt.grid('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(20,8))\n",
    "sns.barplot('Trainings_Attended','Promoted_or_Not',data=train,ax=ax[0])\n",
    "ax[0].set_title('Trainings_Attended vs Promoted_or_Not')\n",
    "sns.factorplot('Trainings_Attended','Promoted_or_Not',data=train,ax=ax[1])\n",
    "ax[1].set_title('Trainings_Attended vs Promoted_or_Not')\n",
    "plt.close(2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Well, its just obivious that these employees were not promoted based on their performance\n",
    "\n",
    "<h3> Without much ado, lets move to the Year_of_birth column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Year_of_birth.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For better view let's plot these percents!\n",
    "x = train.Year_of_birth\n",
    "y = train.Promoted_or_Not\n",
    "\n",
    "plot_graph(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(20,8))\n",
    "sns.barplot('Year_of_birth','Promoted_or_Not',data=train,ax=ax[0])\n",
    "ax[0].set_title('Year_of_birth vs Promoted_or_Not')\n",
    "sns.factorplot('Year_of_birth','Promoted_or_Not',data=train,ax=ax[1])\n",
    "ax[1].set_title('Year_of_birth vs Promoted_or_Not')\n",
    "plt.close(2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(y,x,orient = 'h')\n",
    "plt.grid('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> From these, we can really tell whose who because they are ll closely packed together\n",
    "\n",
    "<h3> Now, moving on to Last_performance_score column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Last_performance_score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test.Last_performance_score\n",
    "y = itrain.Promoted_or_Not\n",
    "\n",
    "plot_graph(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For better view let's plot these percents!\n",
    "x = itrain.Last_performance_score\n",
    "y = itrain.Promoted_or_Not\n",
    "\n",
    "plot_graph(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y,x,orient = 'h')\n",
    "plt.grid('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'NaN' in itrain.Last_performance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(20,8))\n",
    "sns.barplot('Last_performance_score','Promoted_or_Not',data=train,ax=ax[0])\n",
    "ax[0].set_title('Last_performance_score vs Promoted_or_Not')\n",
    "sns.factorplot('Last_performance_score','Promoted_or_Not',data=train,ax=ax[1])\n",
    "ax[1].set_title('Last_performance_score vs Promoted_or_Not')\n",
    "plt.close(2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> We can also see some imbalances especially with those who scored 0.0 points\n",
    "\n",
    "<h3>Ok, lets look at the Year_of_recruitment column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Year_of_recruitment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test.Year_of_recruitment\n",
    "y = itrain.Promoted_or_Not\n",
    "\n",
    "plot_graph(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = itrain.Year_of_recruitment\n",
    "y = itrain.Promoted_or_Not\n",
    "\n",
    "plot_graph(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot('Year_of_recruitment','Promoted_or_Not',hue='Promoted_or_Not',data=train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(18,8))\n",
    "train[['Year_of_recruitment','Promoted_or_Not']].groupby(['Year_of_recruitment']).mean().plot.bar(ax=ax[0])\n",
    "ax[0].set_title('Promoted_or_Not vs Year_of_recruitment')\n",
    "sns.countplot('Year_of_recruitment',hue='Promoted_or_Not',data=train,ax=ax[1])\n",
    "ax[1].set_title('Year_of_recruitment:Promoted or Not')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(20,8))\n",
    "sns.barplot('Year_of_recruitment','Promoted_or_Not',data=train,ax=ax[0])\n",
    "ax[0].set_title('Year_of_recruitment vs Promoted_or_Not')\n",
    "sns.factorplot('Year_of_recruitment','Promoted_or_Not',data=train,ax=ax[1])\n",
    "ax[1].set_title('Year_of_recruitment vs Promoted_or_Not')\n",
    "plt.close(2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> We can also see imbalances here too with this column\n",
    "    \n",
    "<h3> Next! Taking a look at the State_Of_Origin column,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.State_Of_Origin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For better view let's plot these percents!\n",
    "x = itrain.State_Of_Origin\n",
    "y = itrain.Promoted_or_Not\n",
    "\n",
    "plot_graph(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test.State_Of_Origin\n",
    "y = itrain.Promoted_or_Not\n",
    "\n",
    "plot_graph(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot('State_Of_Origin','Promoted_or_Not',hue='State_Of_Origin',data=train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(20,8))\n",
    "sns.barplot('State_Of_Origin','Promoted_or_Not',data=train,ax=ax[0])\n",
    "ax[0].set_title('State_Of_Origin vs Promoted_or_Not')\n",
    "sns.factorplot('State_Of_Origin','Promoted_or_Not',data=train,ax=ax[1])\n",
    "ax[1].set_title('State_Of_Origin vs Promoted_or_Not')\n",
    "plt.close(2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Also in this column, we can see various irregularities in the pattern\n",
    "\n",
    "\n",
    "<h3> Now, lets look at the Foreign_schooled column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Marital_Status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(20,8))\n",
    "sns.barplot('Marital_Status','Promoted_or_Not',data=train,ax=ax[0])\n",
    "ax[0].set_title('Marital_Status vs Promoted_or_Not')\n",
    "sns.factorplot('Marital_Status','Promoted_or_Not',data=train,ax=ax[1])\n",
    "ax[1].set_title('Marital_Status vs Promoted_or_Not')\n",
    "plt.close(2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test.Marital_Status\n",
    "y = itrain.Promoted_or_Not\n",
    "\n",
    "plot_graph(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot('Marital_Status','Promoted_or_Not',hue='Marital_Status',data=train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train.Marital_Status\n",
    "y = train.Promoted_or_Not\n",
    "\n",
    "plot_graph(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.No_of_previous_employers.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For better view let's plot these percents!\n",
    "x = itrain.No_of_previous_employers\n",
    "y = itrain.Promoted_or_Not\n",
    "\n",
    "plot_graph(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.factorplot('No_of_previous_employers','Promoted_or_Not',hue='No_of_previous_employers',data=train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(1,2,figsize=(18,8))\n",
    "itrain['No_of_previous_employers'].value_counts().plot.pie(explode=[0,0.1,0.2,0.3,0.4,0.5,0.6],autopct='%1.1f%%',ax=ax[0], shadow=True)\n",
    "ax[0].set_title('No_of_previous_employers vs promotion')\n",
    "ax[0].set_ylabel('No_of_previous_employers')\n",
    "sns.factorplot('No_of_previous_employers', 'Promoted_or_Not',data=itrain,ax=ax[1])\n",
    "ax[1].set_title('No_of_previous_employers vs promotion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Here also, we can basically see the irregularity in thr promoting pattern\n",
    "    \n",
    "<h3> So now, we are basically done with visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Now, lets Label Encode and One Hot Encode our data, where neccesary and drop few unimportant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "itrain = pd.get_dummies(train, columns = ['Channel_of_Recruitment','Marital_Status', 'Division', 'Previous_IntraDepartmental_Movement', 'State_Of_Origin', 'Gender'])\n",
    "itest = pd.get_dummies(test, columns = ['Channel_of_Recruitment', 'Marital_Status', 'Division', 'Previous_IntraDepartmental_Movement', 'State_Of_Origin', 'Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "itrain['Qualification'][itrain['Qualification'] == 'MSc, MBA and PhD'] = 2\n",
    "itrain['Qualification'][itrain['Qualification'] == 'First Degree or HND'] = 0\n",
    "itrain['Qualification'][itrain['Qualification'] == 'Non-University Education'] = 1\n",
    "\n",
    "\n",
    "itest['Qualification'][itest['Qualification'] == 'MSc, MBA and PhD'] = 2\n",
    "itest['Qualification'][itest['Qualification'] == 'First Degree or HND'] = 0\n",
    "itest['Qualification'][itest['Qualification'] == 'Non-University Education'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Marital_Status'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-5ba7b250cd32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mitrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMarital_Status\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   4374\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4375\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4376\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4378\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Marital_Status'"
     ]
    }
   ],
   "source": [
    "itrain.Marital_Status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Marital_Status'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3077\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3078\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Marital_Status'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-9c13d2a552d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mitrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Marital_Status'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Marital_Status'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'MSc, MBA and PhD'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mitrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Marital_Status'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Marital_Status'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'First Degree or HND'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mitrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Marital_Status'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Marital_Status'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Non-University Education'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2686\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2687\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2688\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2693\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2695\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2697\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2489\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   4113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4114\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4115\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3078\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Marital_Status'"
     ]
    }
   ],
   "source": [
    "itrain['Marital_Status'][itrain['Marital_Status'] == 'MSc, MBA and PhD'] = 2\n",
    "itrain['Marital_Status'][itrain['Marital_Status'] == 'First Degree or HND'] = 0\n",
    "itrain['Marital_Status'][itrain['Marital_Status'] == 'Non-University Education'] = 1\n",
    "\n",
    "\n",
    "itest['Marital_Status'][itest['Marital_Status'] == 'MSc, MBA and PhD'] = 2\n",
    "itest['Marital_Status'][itest['Marital_Status'] == 'First Degree or HND'] = 0\n",
    "itest['Marital_Status'][itest['Marital_Status'] == 'Non-University Education'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "itrain['Targets_met'][itrain['Targets_met'] == 1] = 0\n",
    "itrain['Targets_met'][itrain['Targets_met'] == 0] = 1\n",
    "\n",
    "itest['Targets_met'][itest['Targets_met'] == 1] = 0\n",
    "itest['Targets_met'][itest['Targets_met'] == 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "itrain['Previous_Award'][itrain['Previous_Award'] == 1] = 0\n",
    "itrain['Previous_Award'][itrain['Previous_Award'] == 0] = 1\n",
    "\n",
    "itest['Previous_Award'][itest['Previous_Award'] == 1] = 0\n",
    "itest['Previous_Award'][itest['Previous_Award'] == 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "itrain.Foreign_schooled[itrain.Foreign_schooled == 'Yes'] = 0\n",
    "itrain.Foreign_schooled[itrain.Foreign_schooled == 'No'] = 1\n",
    "\n",
    "itest.Foreign_schooled[itest.Foreign_schooled == 'Yes'] = 0\n",
    "itest.Foreign_schooled[itest.Foreign_schooled == 'No'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "itrain.Past_Disciplinary_Action[itrain.Past_Disciplinary_Action == 'No'] = 0\n",
    "itrain.Past_Disciplinary_Action[itrain.Past_Disciplinary_Action == 'Yes'] = 1\n",
    "\n",
    "itest.Past_Disciplinary_Action[itest.Past_Disciplinary_Action == 'No'] = 0\n",
    "itest.Past_Disciplinary_Action[itest.Past_Disciplinary_Action == 'Yes'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "itrain['Last_performance_score'][itrain['Last_performance_score'] == 12.5] = 0\n",
    "itrain['Last_performance_score'][itrain['Last_performance_score'] == 10.0] = 1\n",
    "itrain['Last_performance_score'][itrain['Last_performance_score'] == 7.5] = 2\n",
    "itrain['Last_performance_score'][itrain['Last_performance_score'] == 5.0] = 3\n",
    "itrain['Last_performance_score'][itrain['Last_performance_score'] == 2.5] = 4\n",
    "itrain['Last_performance_score'][itrain['Last_performance_score'] == 0.0] = 5\n",
    "\n",
    "\n",
    "itest['Last_performance_score'][itest['Last_performance_score'] == 12.5] = 0\n",
    "itest['Last_performance_score'][itest['Last_performance_score'] == 10.0] = 1\n",
    "itest['Last_performance_score'][itest['Last_performance_score'] == 7.5] = 2\n",
    "itest['Last_performance_score'][itest['Last_performance_score'] == 5.0] = 3\n",
    "itest['Last_performance_score'][itest['Last_performance_score'] == 2.5] = 4\n",
    "itest['Last_performance_score'][itest['Last_performance_score'] == 0.0] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "itrain['Trainings_Attended'][itrain['Trainings_Attended'] == 11] = 0\n",
    "itrain['Trainings_Attended'][itrain['Trainings_Attended'] == 10] = 1\n",
    "itrain['Trainings_Attended'][itrain['Trainings_Attended'] == 9] = 2\n",
    "itrain['Trainings_Attended'][itrain['Trainings_Attended'] == 8] = 3\n",
    "itrain['Trainings_Attended'][itrain['Trainings_Attended'] == 7] = 4\n",
    "itrain['Trainings_Attended'][itrain['Trainings_Attended'] == 6] = 5\n",
    "itrain['Trainings_Attended'][itrain['Trainings_Attended'] == 5] = 6\n",
    "itrain['Trainings_Attended'][itrain['Trainings_Attended'] == 4] = 7\n",
    "itrain['Trainings_Attended'][itrain['Trainings_Attended'] == 3] = 8\n",
    "itrain['Trainings_Attended'][itrain['Trainings_Attended'] == 2] = 9\n",
    "\n",
    "\n",
    "itest['Trainings_Attended'][itest['Trainings_Attended'] == 11] = 0\n",
    "itest['Trainings_Attended'][itest['Trainings_Attended'] == 9] = 1\n",
    "itest['Trainings_Attended'][itest['Trainings_Attended'] == 8] = 2\n",
    "itest['Trainings_Attended'][itest['Trainings_Attended'] == 7] = 3\n",
    "itest['Trainings_Attended'][itest['Trainings_Attended'] == 6] = 4\n",
    "itest['Trainings_Attended'][itest['Trainings_Attended'] == 5] = 5\n",
    "itest['Trainings_Attended'][itest['Trainings_Attended'] == 4] = 6\n",
    "itest['Trainings_Attended'][itest['Trainings_Attended'] == 3] = 7\n",
    "itest['Trainings_Attended'][itest['Trainings_Attended'] == 2] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = itest[itest.columns]\n",
    "z = itrain[itrain.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promoted_or_Not\n",
      "Year_of_birth_1950\n",
      "Year_of_birth_1952\n",
      "Year_of_birth_1955\n",
      "Year_of_birth_1956\n",
      "Year_of_birth_1957\n"
     ]
    }
   ],
   "source": [
    "# to write a function that compares the itest and itrain\n",
    "# and checks for columns present in the itrain but absent in the itest\n",
    "for i in z:\n",
    "    if i in y:\n",
    "        pass\n",
    "    else:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "itrain.drop([, 'Year_of_birth'], axis=1, inplace=True)\n",
    "itest.drop([, 'Year_of_birth'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "itrain.drop(['Year_of_birth_1950', 'Year_of_birth_1952', 'Year_of_birth_1955', 'Year_of_birth_1956', 'Year_of_birth_1957'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "itrain['No_of_previous_employers'][itrain['No_of_previous_employers'] == 'More than 5'] = 0\n",
    "itrain['No_of_previous_employers'][itrain['No_of_previous_employers'] == 5] = 1\n",
    "itrain['No_of_previous_employers'][itrain['No_of_previous_employers'] == 4] = 2\n",
    "itrain['No_of_previous_employers'][itrain['No_of_previous_employers'] == 3] = 3\n",
    "itrain['No_of_previous_employers'][itrain['No_of_previous_employers'] == 2] = 4\n",
    "itrain['No_of_previous_employers'][itrain['No_of_previous_employers'] == 1] = 5\n",
    "itrain['No_of_previous_employers'][itrain['No_of_previous_employers'] == 0] = 6\n",
    "\n",
    "itest['No_of_previous_employers'][itest['No_of_previous_employers'] == 'More than 5'] = 0\n",
    "itest['No_of_previous_employers'][itest['No_of_previous_employers'] == 5] = 1\n",
    "itest['No_of_previous_employers'][itest['No_of_previous_employers'] == 4] = 2\n",
    "itest['No_of_previous_employers'][itest['No_of_previous_employers'] == 3] = 3\n",
    "itest['No_of_previous_employers'][itest['No_of_previous_employers'] == 2] = 4\n",
    "itest['No_of_previous_employers'][itest['No_of_previous_employers'] == 1] = 5\n",
    "itest['No_of_previous_employers'][itest['No_of_previous_employers'] == 0] = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Some of these columns are not integers. Some are objects, category, etc.\n",
    "Lets convert it all to numeric form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "itrain.Qualification = pd.to_numeric(itrain.Qualification)\n",
    "itrain.Foreign_schooled = pd.to_numeric(itrain.Foreign_schooled)\n",
    "itrain.Training_score_average = pd.to_numeric(itrain.Training_score_average)\n",
    "itrain.Past_Disciplinary_Action = pd.to_numeric(itrain.Past_Disciplinary_Action)\n",
    "itrain.No_of_previous_employers = pd.to_numeric(itrain.No_of_previous_employers)\n",
    "itrain.Last_performance_score = pd.to_numeric(itrain.Last_performance_score)\n",
    "\n",
    "itest.Qualification = pd.to_numeric(itest.Qualification)\n",
    "itest.Foreign_schooled = pd.to_numeric(itest.Foreign_schooled)\n",
    "itest.Past_Disciplinary_Action = pd.to_numeric(itest.Past_Disciplinary_Action)\n",
    "itest.No_of_previous_employers = pd.to_numeric(itest.No_of_previous_employers)\n",
    "itest.Training_score_average = pd.to_numeric(itest.Training_score_average)\n",
    "itest.Last_performance_score = pd.to_numeric(itest.Last_performance_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38312, 111), (16496, 110))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itrain.shape, itest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Some of these columns contain null values. \n",
    "Lets fill them up with their mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in itrain.columns:\n",
    "    itrain[i].fillna(itrain[i].mode()[0], inplace = True)\n",
    "    \n",
    "for i in itest.columns:\n",
    "    itest[i].fillna(itest[i].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Lets check to see if thats all done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itrain.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets assign a variable to EmployeeNo and drop it\n",
    "target_Id = itest.EmployeeNo\n",
    "itrain.drop(['EmployeeNo'], axis=1, inplace=True)\n",
    "itest.drop(['EmployeeNo'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create a variable for the column we are to predict and drop it\n",
    "target = itrain.Promoted_or_Not\n",
    "itrain.drop(['Promoted_or_Not'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itrain.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itest.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Since thats all done, Lets move to the next stage!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Making Predictions Using Machine Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the data is highly imbalanced, we can upsample the column\n",
    "# Creating a function \"using_smote\"\n",
    "def using_smote(X, y):\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    sm = SMOTE()\n",
    "    X, y = sm.fit_sample(X, y)\n",
    "    return X, y\n",
    "# Using the fuction on the itrain and target \n",
    "train_val, target_val = using_smote(itrain, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the fuction on the itrain and target \n",
    "train_val, target_val = using_smote(itrain, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train,y_test= train_test_split(itrain, target , test_size = 0.22, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38312, 109), (16496, 109))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itrain.shape, itest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the machine models to be used\n",
    "from sklearn.ensemble import RandomForestClassifier #Random Forest\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# import the tools for metrics\n",
    "from sklearn.model_selection import train_test_split #training and testing data split\n",
    "from sklearn import metrics #accuracy measure\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>* Using Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9994980423652243, 0.9298849211057065)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=270, random_state=3, max_features='auto', n_jobs=4, bootstrap=True, class_weight=None, criterion='gini')\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_train, y_train),model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1_score is 0.3322033898305085\n"
     ]
    }
   ],
   "source": [
    "# predict using the X_test\n",
    "pred1 = model.predict(x_test)\n",
    "# Get the f1 score\n",
    "print('The f1_score is', f1_score(pred1, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lassification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96      8264\n",
      "           1       0.20      0.89      0.33       165\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      8429\n",
      "   macro avg       0.60      0.91      0.65      8429\n",
      "weighted avg       0.98      0.93      0.95      8429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# see the overall performance of the data\n",
    "from sklearn.metrics import classification_report\n",
    "print('lassification_report')\n",
    "print(classification_report(pred1, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7691   18]\n",
      " [ 573  147]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict for the itest data \n",
    "pred1a = model.predict(itest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(data = {'EmployeeNo':target_Id, 'Promoted_or_Not':pred1a})\n",
    "output.to_csv(path_or_buf = 'rand-6bumiepredi.csv', index = False, quoting = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Using the Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.5342           0.0172            2.74m\n",
      "         2           0.5228           0.0126            2.64m\n",
      "         3           0.5179           0.0090            2.58m\n",
      "         4           0.5006           0.0104            2.63m\n",
      "         5           0.5031           0.0061            2.54m\n",
      "         6           0.4960           0.0039            2.63m\n",
      "         7           0.4825           0.0091            2.58m\n",
      "         8           0.4818           0.0056            2.72m\n",
      "         9           0.4782           0.0022            2.69m\n",
      "        10           0.4727           0.0021            2.68m\n",
      "        11           0.4692           0.0020            2.70m\n",
      "        12           0.4716           0.0035            2.69m\n",
      "        13           0.4657           0.0019            2.67m\n",
      "        14           0.4649           0.0009            2.65m\n",
      "        15           0.4604           0.0036            2.63m\n",
      "        16           0.4571           0.0048            2.63m\n",
      "        17           0.4613           0.0001            2.58m\n",
      "        18           0.4564          -0.0000            2.62m\n",
      "        19           0.4555           0.0015            2.61m\n",
      "        20           0.4424           0.0018            2.64m\n",
      "        21           0.4484           0.0017            2.69m\n",
      "        22           0.4431           0.0006            2.80m\n",
      "        23           0.4447           0.0001            2.93m\n",
      "        24           0.4418          -0.0002            2.95m\n",
      "        25           0.4379           0.0009            3.02m\n",
      "        26           0.4418           0.0010            3.03m\n",
      "        27           0.4357           0.0005            3.01m\n",
      "        28           0.4318           0.0004            3.00m\n",
      "        29           0.4347          -0.0005            2.98m\n",
      "        30           0.4300          -0.0003            2.95m\n",
      "        31           0.4313          -0.0002            2.94m\n",
      "        32           0.4400          -0.0004            2.91m\n",
      "        33           0.4325          -0.0004            2.88m\n",
      "        34           0.4334          -0.0001            2.84m\n",
      "        35           0.4389           0.0009            2.80m\n",
      "        36           0.4277           0.0005            2.78m\n",
      "        37           0.4258           0.0008            2.75m\n",
      "        38           0.4299           0.0013            2.74m\n",
      "        39           0.4205          -0.0001            2.70m\n",
      "        40           0.4246          -0.0003            2.67m\n",
      "        41           0.4242          -0.0001            2.66m\n",
      "        42           0.4223           0.0022            2.64m\n",
      "        43           0.4236           0.0000            2.61m\n",
      "        44           0.4204          -0.0000            2.58m\n",
      "        45           0.4243          -0.0002            2.57m\n",
      "        46           0.4208           0.0008            2.56m\n",
      "        47           0.4215          -0.0000            2.56m\n",
      "        48           0.4212           0.0003            2.56m\n",
      "        49           0.4191           0.0004            2.59m\n",
      "        50           0.4223          -0.0005            2.62m\n",
      "        51           0.4175          -0.0001            2.61m\n",
      "        52           0.4181           0.0002            2.59m\n",
      "        53           0.4171          -0.0002            2.57m\n",
      "        54           0.4185          -0.0002            2.56m\n",
      "        55           0.4125          -0.0003            2.53m\n",
      "        56           0.4167          -0.0003            2.51m\n",
      "        57           0.4108          -0.0002            2.50m\n",
      "        58           0.4142          -0.0000            2.47m\n",
      "        59           0.4167          -0.0003            2.45m\n",
      "        60           0.4102          -0.0006            2.43m\n",
      "        61           0.4135          -0.0004            2.40m\n",
      "        62           0.4127          -0.0005            2.38m\n",
      "        63           0.4074          -0.0005            2.36m\n",
      "        64           0.4114          -0.0002            2.36m\n",
      "        65           0.4112          -0.0001            2.35m\n",
      "        66           0.4124          -0.0007            2.34m\n",
      "        67           0.4130          -0.0005            2.34m\n",
      "        68           0.4108          -0.0004            2.34m\n",
      "        69           0.4091           0.0006            2.33m\n",
      "        70           0.4072          -0.0004            2.32m\n",
      "        71           0.4100          -0.0004            2.32m\n",
      "        72           0.4131           0.0002            2.32m\n",
      "        73           0.4072          -0.0004            2.33m\n",
      "        74           0.4099          -0.0002            2.34m\n",
      "        75           0.4048          -0.0003            2.36m\n",
      "        76           0.4088          -0.0001            2.36m\n",
      "        77           0.4104          -0.0004            2.37m\n",
      "        78           0.4003          -0.0009            2.35m\n",
      "        79           0.4023          -0.0008            2.34m\n",
      "        80           0.4030           0.0002            2.32m\n",
      "        81           0.4060          -0.0003            2.30m\n",
      "        82           0.4009          -0.0002            2.29m\n",
      "        83           0.4045           0.0000            2.28m\n",
      "        84           0.4010          -0.0001            2.27m\n",
      "        85           0.4001          -0.0007            2.26m\n",
      "        86           0.4029          -0.0001            2.24m\n",
      "        87           0.4011          -0.0005            2.22m\n",
      "        88           0.3953          -0.0010            2.21m\n",
      "        89           0.3998          -0.0003            2.19m\n",
      "        90           0.4066          -0.0010            2.17m\n",
      "        91           0.3959          -0.0005            2.16m\n",
      "        92           0.3998          -0.0001            2.14m\n",
      "        93           0.3985          -0.0006            2.13m\n",
      "        94           0.3957           0.0001            2.12m\n",
      "        95           0.3971          -0.0008            2.10m\n",
      "        96           0.3980          -0.0008            2.09m\n",
      "        97           0.3961          -0.0005            2.07m\n",
      "        98           0.3977          -0.0002            2.06m\n",
      "        99           0.3954          -0.0004            2.04m\n",
      "       100           0.3972          -0.0005            2.03m\n",
      "       101           0.3921          -0.0003            2.02m\n",
      "       102           0.3994          -0.0004            2.01m\n",
      "       103           0.3970          -0.0011            2.00m\n",
      "       104           0.3908           0.0002            2.00m\n",
      "       105           0.3965          -0.0002            2.00m\n",
      "       106           0.3842          -0.0002            1.99m\n",
      "       107           0.3925          -0.0007            1.99m\n",
      "       108           0.3956          -0.0004            1.98m\n",
      "       109           0.3876          -0.0004            1.98m\n",
      "       110           0.3880          -0.0005            1.97m\n",
      "       111           0.3948          -0.0008            1.96m\n",
      "       112           0.3946           0.0000            1.95m\n",
      "       113           0.3898          -0.0005            1.94m\n",
      "       114           0.3901          -0.0005            1.94m\n",
      "       115           0.3958          -0.0002            1.93m\n",
      "       116           0.3898          -0.0008            1.92m\n",
      "       117           0.3858          -0.0007            1.91m\n",
      "       118           0.3878          -0.0003            1.89m\n",
      "       119           0.3883          -0.0002            1.88m\n",
      "       120           0.3891          -0.0003            1.86m\n",
      "       121           0.3905          -0.0006            1.85m\n",
      "       122           0.3919          -0.0008            1.85m\n",
      "       123           0.3899          -0.0004            1.84m\n",
      "       124           0.3878          -0.0004            1.83m\n",
      "       125           0.3875          -0.0006            1.82m\n",
      "       126           0.3853          -0.0007            1.82m\n",
      "       127           0.3833          -0.0006            1.81m\n",
      "       128           0.3899          -0.0003            1.80m\n",
      "       129           0.3884          -0.0005            1.79m\n",
      "       130           0.3865          -0.0005            1.78m\n",
      "       131           0.3856          -0.0004            1.76m\n",
      "       132           0.3861          -0.0002            1.75m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       133           0.3897          -0.0008            1.75m\n",
      "       134           0.3826          -0.0003            1.74m\n",
      "       135           0.3823          -0.0005            1.73m\n",
      "       136           0.3860          -0.0005            1.72m\n",
      "       137           0.3854          -0.0008            1.71m\n",
      "       138           0.3859          -0.0003            1.70m\n",
      "       139           0.3851          -0.0006            1.69m\n",
      "       140           0.3800          -0.0003            1.68m\n",
      "       141           0.3804          -0.0000            1.67m\n",
      "       142           0.3800          -0.0005            1.66m\n",
      "       143           0.3836          -0.0001            1.64m\n",
      "       144           0.3822          -0.0007            1.63m\n",
      "       145           0.3838          -0.0006            1.62m\n",
      "       146           0.3809          -0.0006            1.62m\n",
      "       147           0.3781          -0.0005            1.61m\n",
      "       148           0.3766          -0.0004            1.60m\n",
      "       149           0.3776          -0.0005            1.59m\n",
      "       150           0.3789          -0.0001            1.59m\n",
      "       151           0.3767          -0.0004            1.58m\n",
      "       152           0.3771          -0.0005            1.56m\n",
      "       153           0.3781          -0.0006            1.55m\n",
      "       154           0.3762          -0.0006            1.54m\n",
      "       155           0.3807          -0.0001            1.52m\n",
      "       156           0.3731          -0.0004            1.51m\n",
      "       157           0.3794          -0.0001            1.50m\n",
      "       158           0.3788          -0.0002            1.49m\n",
      "       159           0.3756          -0.0007            1.48m\n",
      "       160           0.3746          -0.0004            1.47m\n",
      "       161           0.3750          -0.0005            1.46m\n",
      "       162           0.3738          -0.0003            1.45m\n",
      "       163           0.3742          -0.0008            1.44m\n",
      "       164           0.3771          -0.0009            1.43m\n",
      "       165           0.3721          -0.0003            1.41m\n",
      "       166           0.3693          -0.0003            1.40m\n",
      "       167           0.3710          -0.0004            1.39m\n",
      "       168           0.3776          -0.0004            1.38m\n",
      "       169           0.3764          -0.0005            1.37m\n",
      "       170           0.3744          -0.0002            1.36m\n",
      "       171           0.3708          -0.0006            1.34m\n",
      "       172           0.3730          -0.0005            1.33m\n",
      "       173           0.3727          -0.0003            1.33m\n",
      "       174           0.3655          -0.0007            1.32m\n",
      "       175           0.3712          -0.0004            1.31m\n",
      "       176           0.3718          -0.0006            1.30m\n",
      "       177           0.3729          -0.0003            1.29m\n",
      "       178           0.3674          -0.0007            1.28m\n",
      "       179           0.3685          -0.0003            1.27m\n",
      "       180           0.3758          -0.0006            1.26m\n",
      "       181           0.3680          -0.0004            1.24m\n",
      "       182           0.3643          -0.0003            1.23m\n",
      "       183           0.3691          -0.0005            1.22m\n",
      "       184           0.3704          -0.0006            1.21m\n",
      "       185           0.3684          -0.0007            1.19m\n",
      "       186           0.3637          -0.0006            1.18m\n",
      "       187           0.3718          -0.0003            1.17m\n",
      "       188           0.3687          -0.0004            1.16m\n",
      "       189           0.3632          -0.0005            1.15m\n",
      "       190           0.3646          -0.0006            1.13m\n",
      "       191           0.3641          -0.0007            1.12m\n",
      "       192           0.3681          -0.0003            1.11m\n",
      "       193           0.3653          -0.0004            1.10m\n",
      "       194           0.3679          -0.0004            1.09m\n",
      "       195           0.3676          -0.0004            1.08m\n",
      "       196           0.3667          -0.0006            1.06m\n",
      "       197           0.3675          -0.0003            1.05m\n",
      "       198           0.3660          -0.0004            1.04m\n",
      "       199           0.3648          -0.0002            1.03m\n",
      "       200           0.3672          -0.0005            1.02m\n",
      "       201           0.3634          -0.0004            1.01m\n",
      "       202           0.3618          -0.0007            1.00m\n",
      "       203           0.3653          -0.0006           59.72s\n",
      "       204           0.3648          -0.0006           59.22s\n",
      "       205           0.3605          -0.0006           58.71s\n",
      "       206           0.3648          -0.0004           58.09s\n",
      "       207           0.3578          -0.0005           57.42s\n",
      "       208           0.3618          -0.0004           56.69s\n",
      "       209           0.3630          -0.0007           56.03s\n",
      "       210           0.3632          -0.0009           55.45s\n",
      "       211           0.3618          -0.0006           54.89s\n",
      "       212           0.3661          -0.0007           54.23s\n",
      "       213           0.3563          -0.0009           53.52s\n",
      "       214           0.3643          -0.0009           52.81s\n",
      "       215           0.3593          -0.0005           52.14s\n",
      "       216           0.3593          -0.0004           51.57s\n",
      "       217           0.3614          -0.0006           50.95s\n",
      "       218           0.3562          -0.0006           50.52s\n",
      "       219           0.3588          -0.0005           49.90s\n",
      "       220           0.3567          -0.0009           49.35s\n",
      "       221           0.3605          -0.0008           48.72s\n",
      "       222           0.3605          -0.0004           48.08s\n",
      "       223           0.3567          -0.0005           47.48s\n",
      "       224           0.3601          -0.0003           46.82s\n",
      "       225           0.3607          -0.0003           46.21s\n",
      "       226           0.3553          -0.0008           45.69s\n",
      "       227           0.3597          -0.0007           45.22s\n",
      "       228           0.3581          -0.0010           44.69s\n",
      "       229           0.3605          -0.0007           44.37s\n",
      "       230           0.3588          -0.0001           43.86s\n",
      "       231           0.3630          -0.0009           43.45s\n",
      "       232           0.3590          -0.0006           42.98s\n",
      "       233           0.3581          -0.0009           42.71s\n",
      "       234           0.3582          -0.0009           42.16s\n",
      "       235           0.3581          -0.0003           41.56s\n",
      "       236           0.3570          -0.0006           40.90s\n",
      "       237           0.3531          -0.0007           40.25s\n",
      "       238           0.3567          -0.0003           39.64s\n",
      "       239           0.3552          -0.0004           39.06s\n",
      "       240           0.3545          -0.0007           38.42s\n",
      "       241           0.3542          -0.0003           37.80s\n",
      "       242           0.3547          -0.0006           37.21s\n",
      "       243           0.3537          -0.0008           36.62s\n",
      "       244           0.3512          -0.0002           36.09s\n",
      "       245           0.3529          -0.0005           35.51s\n",
      "       246           0.3591          -0.0004           34.95s\n",
      "       247           0.3534          -0.0004           34.32s\n",
      "       248           0.3509          -0.0008           33.68s\n",
      "       249           0.3484          -0.0007           32.99s\n",
      "       250           0.3520          -0.0007           32.37s\n",
      "       251           0.3542          -0.0006           31.72s\n",
      "       252           0.3579          -0.0003           31.19s\n",
      "       253           0.3560          -0.0002           30.58s\n",
      "       254           0.3510          -0.0005           30.04s\n",
      "       255           0.3523          -0.0004           29.56s\n",
      "       256           0.3576          -0.0003           28.93s\n",
      "       257           0.3489          -0.0005           28.30s\n",
      "       258           0.3522          -0.0007           27.66s\n",
      "       259           0.3520          -0.0004           26.99s\n",
      "       260           0.3512          -0.0003           26.33s\n",
      "       261           0.3556          -0.0007           25.72s\n",
      "       262           0.3504          -0.0006           25.12s\n",
      "       263           0.3504          -0.0004           24.54s\n",
      "       264           0.3489          -0.0008           23.93s\n",
      "       265           0.3490          -0.0003           23.28s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       266           0.3466          -0.0004           22.62s\n",
      "       267           0.3501          -0.0004           21.96s\n",
      "       268           0.3466          -0.0004           21.31s\n",
      "       269           0.3506          -0.0002           20.63s\n",
      "       270           0.3490          -0.0005           19.95s\n",
      "       271           0.3455          -0.0004           19.28s\n",
      "       272           0.3518          -0.0006           18.60s\n",
      "       273           0.3403          -0.0004           17.92s\n",
      "       274           0.3477          -0.0002           17.25s\n",
      "       275           0.3476          -0.0002           16.57s\n",
      "       276           0.3493          -0.0008           15.90s\n",
      "       277           0.3416          -0.0005           15.23s\n",
      "       278           0.3461          -0.0005           14.56s\n",
      "       279           0.3436          -0.0004           13.88s\n",
      "       280           0.3440          -0.0003           13.22s\n",
      "       281           0.3465          -0.0005           12.55s\n",
      "       282           0.3433          -0.0007           11.88s\n",
      "       283           0.3453          -0.0004           11.21s\n",
      "       284           0.3436          -0.0006           10.56s\n",
      "       285           0.3454          -0.0005            9.90s\n",
      "       286           0.3452          -0.0005            9.26s\n",
      "       287           0.3449          -0.0008            8.60s\n",
      "       288           0.3404          -0.0002            7.95s\n",
      "       289           0.3412          -0.0005            7.29s\n",
      "       290           0.3401          -0.0005            6.63s\n",
      "       291           0.3418          -0.0006            5.96s\n",
      "       292           0.3413          -0.0004            5.30s\n",
      "       293           0.3415          -0.0007            4.63s\n",
      "       294           0.3417          -0.0004            3.97s\n",
      "       295           0.3417          -0.0003            3.31s\n",
      "       296           0.3390          -0.0004            2.65s\n",
      "       297           0.3408          -0.0008            1.99s\n",
      "       298           0.3373          -0.0009            1.32s\n",
      "       299           0.3451          -0.0005            0.66s\n",
      "       300           0.3400          -0.0002            0.00s\n",
      "Accuracy score for x_train is  0.9447177324900445\n",
      "Accuracy score for x_test is  0.9380709455451418\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(loss='exponential', learning_rate = 0.2,subsample = 0.7, n_estimators = 300, random_state=5, max_features='auto',\n",
    "                                   max_depth=4, warm_start=True, min_samples_leaf=5, min_samples_split=4, )\n",
    "model.fit(x_train, y_train) \n",
    "print('Accuracy score for x_train is ', model.score(x_train, y_train))\n",
    "print('Accuracy score for x_test is ', model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict using the x_test\n",
    "pred2 = model.predict(x_test)\n",
    "# predict using the itest data\n",
    "pred2a = model.predict(itest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1_score is 0.4585062240663901\n"
     ]
    }
   ],
   "source": [
    "# get the f1 score\n",
    "print('The f1_score is',f1_score(pred2, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lassification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      8185\n",
      "           1       0.31      0.91      0.46       244\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      8429\n",
      "   macro avg       0.65      0.92      0.71      8429\n",
      "weighted avg       0.98      0.94      0.95      8429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# see the overall performance of the data\n",
    "from sklearn.metrics import classification_report\n",
    "print('lassification_report')\n",
    "print(classification_report(pred2, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7686   23]\n",
      " [ 499  221]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets Export It To A Csv File\n",
    "output = pd.DataFrame(data = {'EmployeeNo':target_Id, 'Promoted_or_Not':pred2a})\n",
    "output.to_csv(path_or_buf = 'gb-4bumiepredi.csv', index = False, quoting = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>* Using XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy Score For x_test Is :  0.9522805608539973\n",
      "The Accuracy Score For x_test Is :  0.9378336694744335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(learning_rate = 0.2, num_boosting_rounds = 270 , max_depth=10, subsample=0.8)\n",
    "xgb.fit(x_train, y_train)\n",
    "print('The Accuracy Score For x_test Is : ', xgb.score(x_train, y_train)), print('The Accuracy Score For x_test Is : ', xgb.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Lets convert the itest data to an array first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "itest = np.array(itest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [x for x in itrain.columns]\n",
    "\n",
    "itest = pd.DataFrame(itest, columns = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4575569358178053"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3 = xgb.predict(x_test)\n",
    "pred3a = xgb.predict(itest)\n",
    "f1_score(pred3, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lassification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97      8183\n",
      "           1       0.31      0.90      0.46       246\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      8429\n",
      "   macro avg       0.65      0.92      0.71      8429\n",
      "weighted avg       0.98      0.94      0.95      8429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# see the overall performance of the data\n",
    "from sklearn.metrics import classification_report\n",
    "print('lassification_report')\n",
    "print(classification_report(pred3, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(data = {'EmployeeNo':target_Id, 'Promoted_or_Not':pred3a})\n",
    "output.to_csv(path_or_buf = 'xgb-3bumiepredi.csv', index = False, quoting = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Lets try stacking models together to see if we would have a better precision and recall score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [2]\n",
      "metric:       [f1_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [3]\n",
      "\n",
      "model  0:     [RandomForestClassifier]\n",
      "    fold  0:  [0.31699346]\n",
      "    fold  1:  [0.37558685]\n",
      "    fold  2:  [0.33118971]\n",
      "    fold  3:  [0.38425197]\n",
      "    fold  4:  [0.38184664]\n",
      "    ----\n",
      "    MEAN:     [0.35797373] + [0.02816895]\n",
      "    FULL:     [0.35843661]\n",
      "\n",
      "model  1:     [GradientBoostingClassifier]\n",
      "    fold  0:  [0.43193717]\n",
      "    fold  1:  [0.44955300]\n",
      "    fold  2:  [0.44359949]\n",
      "    fold  3:  [0.45959596]\n",
      "    fold  4:  [0.46033810]\n",
      "    ----\n",
      "    MEAN:     [0.44900475] + [0.01059659]\n",
      "    FULL:     [0.44906338]\n",
      "\n",
      "model  2:     [XGBClassifier]\n",
      "    fold  0:  [0.46902655]\n",
      "    fold  1:  [0.49928264]\n",
      "    fold  2:  [0.50578035]\n",
      "    fold  3:  [0.49784173]\n",
      "    fold  4:  [0.48695652]\n",
      "    ----\n",
      "    MEAN:     [0.49177756] + [0.01288433]\n",
      "    FULL:     [0.49188876]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from vecstack import stacking\n",
    "from xgboost import XGBClassifier\n",
    "models = [RandomForestClassifier(n_estimators=270, random_state=3, max_features='auto', n_jobs=2, bootstrap=True, class_weight=None, criterion='gini'), GradientBoostingClassifier(learning_rate = 0.2,subsample=0.8, n_estimators = 270, random_state=5, max_features='auto', max_depth=10), XGBClassifier(learning_rate = 0.2, num_boosting_rounds = 270 , max_depth=10, subsample=0.8)]\n",
    "a_train, a_test = stacking(models,                   \n",
    "                           x_train, y_train, x_test,   \n",
    "                           regression=False, \n",
    "     \n",
    "                           mode='oof_pred_bag', \n",
    "       \n",
    "                           needs_proba=False,\n",
    "         \n",
    "                           save_dir=None, \n",
    "            \n",
    "                           metric=f1_score, \n",
    "    \n",
    "                           n_folds=5, \n",
    "                 \n",
    "                           stratified=True,\n",
    "            \n",
    "                           shuffle=True,  \n",
    "            \n",
    "                           random_state=0,    \n",
    "         \n",
    "                           verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Lets save the predictions from random forest, gradient boosting and xgboost classification as a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test =  pd.DataFrame(pred1a)\n",
    "array = pred2a\n",
    "array1 = pred3a\n",
    "new_test[1] = array\n",
    "new_test[2] = array1\n",
    "new_test = np.array(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_train['1'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Lets now test the new test and the new train(a_train, a_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(a_train, y_train)\n",
    "lr.score(a_train, y_train), lr.score(a_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets test it on the x_test data\n",
    "pred = lr.predict(a_test)\n",
    "# predict using the itest data\n",
    "pred3a = lr.predict(b_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the f1 score\n",
    "f1_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the overall performance of the data\n",
    "from sklearn.metrics import classification_report\n",
    "print('lassification_report')\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(data = {'EmployeeNo':target_Id, 'Promoted_or_Not':pred3a})\n",
    "output.to_csv(path_or_buf = 'lr-1bumiepredi.csv', index = False, quoting = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm #support vector Machine\n",
    "model=svm.SVC(kernel='',C=1,gamma=0.1) \n",
    "model.fit(a_train, y_train)\n",
    "model.score(a_train, y_train), model.score(a_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets test it on the x_test data\n",
    "pred = model.predict(a_test)\n",
    "# predict using the itest data\n",
    "pred3a = model.predict(b_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the f1 score\n",
    "f1_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the overall performance of the data\n",
    "from sklearn.metrics import classification_report\n",
    "print('lassification_report')\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(data = {'EmployeeNo':target_Id, 'Promoted_or_Not':pred3a})\n",
    "output.to_csv(path_or_buf = 'svc-1bumiepredi.csv', index = False, quoting = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
